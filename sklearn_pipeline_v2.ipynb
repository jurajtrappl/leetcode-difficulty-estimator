{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ece3af-12da-4755-a86e-9010a8643959",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8fbb5-8f2c-47b3-b4ad-015c0bc40b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import lzma\n",
    "import pickle\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.linear_model\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.neural_network\n",
    "import sklearn.pipeline\n",
    "import sklearn.svm\n",
    "import csv\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d2341-0d7f-47e4-920e-3e76a3d9ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b7ae9-21c6-4f47-8fbb-3e770af226ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--c_n\", default=5, type=int, help=\"Character n-grams\")\n",
    "parser.add_argument(\"--c_tf\", default=\"binary\", type=str, help=\"Character TF type\")\n",
    "parser.add_argument(\"--c_mf\", default=None, type=int, help=\"Character max features\")\n",
    "parser.add_argument(\"--c_wb\", default=False, action=\"store_true\", help=\"Character wb\")\n",
    "parser.add_argument(\"--model\", default=\"mlp_c\", type=str, help=\"Model type\")\n",
    "parser.add_argument(\"--w_n\", default=3, type=int, help=\"Word n-grams\")\n",
    "parser.add_argument(\"--w_tf\", default=\"log\", type=str, help=\"Word TF type\")\n",
    "parser.add_argument(\"--w_mf\", default=None, type=int, help=\"Word max features\")\n",
    "parser.add_argument(\"--hidden_layer\", default=(64,), type=int, help=\"Hidden layer size\")\n",
    "parser.add_argument(\"--alpha\", default=0.0005, type=float, help=\"Alpha for L2 regularization\")\n",
    "parser.add_argument(\"--activation\", default=\"relu\", type=str, help=\"Activation function\")\n",
    "\n",
    "args = parser.parse_args([] if \"__file__\" not in globals() else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ccec9-ac1d-477d-ab75-0fa1a88d9624",
   "metadata": {},
   "source": [
    "1. Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26eabef-5702-4ecd-a69f-ee119de0de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('leetcode_problems_dataset.json', 'r') as f:\n",
    "        problems = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576ff1a-d653-472e-93de-7f669484231a",
   "metadata": {},
   "source": [
    "Remove HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c369a02-8507-4ad6-b5c8-2b264394d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_without_html = []\n",
    "for problem_name, problem_data in tqdm(problems.items()):\n",
    "    if not problem_data[\"content\"]:\n",
    "        continue\n",
    "\n",
    "    problems_without_html.append((BeautifulSoup(problem_data[\"content\"], \"html.parser\").get_text(), problem_data[\"difficulty\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd33ce9-ab7f-4e82-bfb5-dc8a5c5b0a09",
   "metadata": {},
   "source": [
    "Create X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df914d-d2f5-4ba9-a7b8-0e77585ddea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "difficulties_int = { \"Easy\": 0, \"Medium\": 1, \"Hard\": 2 }\n",
    "for problem_description, difficulty in problems_without_html:\n",
    "    X.append(problem_description)\n",
    "    y.append(difficulties_int[difficulty])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb2305b-b992-4b05-95d5-3a2884eec9df",
   "metadata": {},
   "source": [
    "Prepare downsampling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff8c0b-537d-4c4f-95ec-ba5f6ab8e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_dataset(features, labels):\n",
    "        \"\"\"\n",
    "        Downsamples the dataset to have an equal distribution of classes.\n",
    "\n",
    "        Parameters:\n",
    "        X (list): Feature data.\n",
    "        y (list): Corresponding labels.\n",
    "\n",
    "        Returns:\n",
    "        tuple: Downsampled feature data and labels.\n",
    "        \"\"\"\n",
    "        paired_data = list(zip(features, labels))\n",
    "        class_distribution = Counter(labels)\n",
    "\n",
    "        min_samples = min(class_distribution.values())\n",
    "\n",
    "        downsampled_data = []\n",
    "        class_counts = {cls: 0 for cls in class_distribution.keys()}\n",
    "\n",
    "        for data, label in paired_data:\n",
    "            if class_counts[label] < min_samples:\n",
    "                downsampled_data.append((data, label))\n",
    "                class_counts[label] += 1\n",
    "\n",
    "        features_downsampled, labels_downsampled = zip(*downsampled_data)\n",
    "\n",
    "        return list(features_downsampled), list(labels_downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7eaade-6bee-4be9-b081-949838e490c3",
   "metadata": {},
   "source": [
    "Downsample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9133c76-ea62-4bee-b4c9-48fe1b7cecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = downsample_dataset(X, y)\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7dd86-6862-44a6-96f8-682f59094bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=SEED, stratify=y_val)\n",
    "\n",
    "# X_train, X_val, X_test, y_train, y_val, y_test = np.array(X_train), np.array(X_val), np.array(X_test), np.array(y_train), np.array(y_val), np.array(y_test)\n",
    "\n",
    "# # combine train and val\n",
    "# X_train = np.concatenate((X_train, X_val))\n",
    "# y_train = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd991b-a88d-43ca-a550-3e6f9cf2440a",
   "metadata": {},
   "source": [
    "Define model pipeline\n",
    "- TF-IDF\n",
    "    - word level\n",
    "    - character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe033a-e669-4aa0-96f1-3752a4cd19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.pipeline.Pipeline([\n",
    "    (\"feature_extraction\",\n",
    "        sklearn.pipeline.FeatureUnion(([\n",
    "            (\"word_level\", sklearn.feature_extraction.text.TfidfVectorizer(\n",
    "                lowercase=True, analyzer=\"word\", ngram_range=(1, args.w_n),\n",
    "                binary=args.w_tf == \"binary\", sublinear_tf=args.w_tf == \"log\", max_features=args.w_mf)),\n",
    "        ] if args.w_n else []) + ([\n",
    "            (\"char_level\", sklearn.feature_extraction.text.TfidfVectorizer(\n",
    "                lowercase=True, analyzer=\"char_wb\" if args.c_wb else \"char\", ngram_range=(1, args.c_n),\n",
    "                binary=args.c_tf == \"binary\", sublinear_tf=args.c_tf == \"log\", max_features=args.c_mf)),\n",
    "        ] if args.c_n else []))),\n",
    "    # (\"truncated_svd\", sklearn.decomposition.TruncatedSVD(n_components=5 random_state=SEED)),\n",
    "    # (\"feature_selection\", sklearn.feature_selection.SelectKBest(f_classif, k=100000)),\n",
    "    (\"feature_selection\", sklearn.feature_selection.SelectPercentile(score_func=f_classif, percentile=5)),\n",
    "    (\"estimator\", {\n",
    "        \"perceptron\": sklearn.linear_model.Perceptron(tol=1e-6, n_jobs=4, early_stopping=True, validation_fraction=0.1, verbose=0, penalty=\"l2\", random_state=SEED),\n",
    "        \"mlp_c\": sklearn.neural_network.MLPClassifier(hidden_layer_sizes=args.hidden_layer, max_iter=100, verbose=0, alpha=args.alpha, early_stopping=True, activation=args.activation),\n",
    "        \"mlp_r\": sklearn.neural_network.MLPRegressor(hidden_layer_sizes=args.hidden_layer, max_iter=100, verbose=1, alpha=args.alpha, early_stopping=True, activation=args.activation),\n",
    "        \"svm\": sklearn.svm.SVC(verbose=0, random_state=SEED),\n",
    "        \"lsvm\": sklearn.svm.LinearSVC(verbose=0, random_state=SEED, penalty=\"l2\"),\n",
    "    }[args.model]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec7e4ba-a744-4807-a69e-e7b4d6674814",
   "metadata": {},
   "source": [
    "Perform 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ad2da-9474-41e4-be76-fd332522c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "f1_scores_macro = []\n",
    "f1_scores_micro = []\n",
    "\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_val)\n",
    "\n",
    "    f1_scores_macro.append(f1_score(y_val, predictions, average='macro'))\n",
    "    f1_scores_micro.append(f1_score(y_val, predictions, average='micro'))\n",
    "\n",
    "avg_f1_score_macro = np.mean(f1_scores_macro)\n",
    "avg_f1_score_micro = np.mean(f1_scores_micro)\n",
    "\n",
    "print('Average Test F1 score (Macro):', avg_f1_score_macro)\n",
    "print('Average Test F1 score (Micro):', avg_f1_score_micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590dfc95-16cb-4f57-86d5-83852b06ce4e",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc4b29-9f30-41bc-be63-09e3ad4beeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "class_labels = ['Easy', 'Medium', 'Hard']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='BuGn', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title(f'Confusion Matrix for {args.model}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig(f\"{args.model}.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "if args.model == \"lsvm\" or args.model == \"svm\":\n",
    "    model_name = f\"{args.model}_{args.w_n}_{args.c_n}\"\n",
    "else:\n",
    "    model_name = f\"{args.model}_{args.w_n}_{args.c_n}_{args.hidden_layer}_{args.alpha}_{args.activation}\"\n",
    "# with lzma.open(f\"models/{model_name}.pickle\", \"wb\") as model_file:\n",
    "#     pickle.dump(model, model_file)\n",
    "# print(f\"Model saved to models/{model_name}.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a88bce-d9db-49b9-8e90-86443e82db83",
   "metadata": {},
   "source": [
    "### Analysis of mistakes made by models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affcb1e7-a927-429a-af00-60b1e67e29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_easy_was_hard = []\n",
    "predicted_hard_was_easy = []\n",
    "for test_example, target in zip(X_test, y_test):\n",
    "    prediction = model.predict([test_example])\n",
    "    \n",
    "    if prediction == 2 and target == 0:\n",
    "        predicted_hard_was_easy.append(test_example)\n",
    "        \n",
    "    if prediction == 0 and target == 2:\n",
    "        predicted_easy_was_hard.append(test_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cac068-1021-40ba-bfa0-38b7312a4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"{random.choice(predicted_easy_was_hard)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3eddfa-96b5-4bba-bafa-ce4e1846d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"{random.choice(predicted_hard_was_easy)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77956f8c-3d19-4d01-80b9-a48140b4f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_with_maximum = []\n",
    "for example, target in zip(X, y):\n",
    "    if \"maximum\" in example:\n",
    "        problems_with_maximum.append(target)\n",
    "        \n",
    "problems_with_maximum = Counter(problems_with_maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210e13f-e73e-424f-a0ed-d8b1ae88f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulties_maximum, counts_maximum = problems_with_maximum.keys(), problems_with_maximum.values()\n",
    "difficulties_maximum = [\"Easy\", \"Hard\", \"Medium\"]\n",
    "print(problems_with_maximum)\n",
    "\n",
    "plt.pie(counts_maximum, labels=difficulties_maximum, colors=[\"blue\", \"orange\", \"green\"])\n",
    "plt.title(\"Distribution of difficulties of problems that contain \\\"maximum\\\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e48eb6-97de-46cd-af09-56d962a649c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_with_minimum = []\n",
    "for example, target in zip(X, y):\n",
    "    if \"minimum\" in example:\n",
    "        problems_with_minimum.append(target)\n",
    "        \n",
    "problems_with_minimum = Counter(problems_with_minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cc2e7-8a0d-4ec1-83cc-e143ac48ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulties_minimum, counts_minimum = problems_with_minimum.keys(), problems_with_minimum.values()\n",
    "difficulties_minimum = [\"Hard\", \"Easy\", \"Medium\"]\n",
    "print(problems_with_minimum)\n",
    "\n",
    "plt.pie(counts_minimum, labels=difficulties_minimum, colors=[\"orange\", \"blue\", \"green\"])\n",
    "plt.title(\"Distribution of difficulties of problems that contain \\\"minimum\\\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a0e92-dd0e-46e2-8169-26e77e85af6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
